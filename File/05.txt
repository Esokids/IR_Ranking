Why a data scientist warns against always trusting AI’s scientific discoveries

WASHINGTON — We live in a golden age of scientific data, with larger stockpiles of genetic information, 
medical images and astronomical observations than ever before. Artificial intelligence can pore over these 
troves to uncover potential new scientific discoveries much quicker than people ever could. But we should 
not blindly trust AI’s scientific insights, argues data scientist Genevera Allen, until these computer programs can 
better gauge how certain they are in their own results.

AI systems that use machine learning — programs that learn what to do by studying data rather than following 
explicit instructions — can be entrusted with some decisions, says Allen, of Rice University in Houston. Namely, 
AI is reliable for making decisions in areas where humans can easily check their work, like counting craters on
 the moon or predicting earthquake aftershocks (SN: 12/22/18, p. 25).

But more exploratory algorithms that poke around large datasets to identify previously unknown patterns or 
relationships between various features “are very hard to verify,” Allen said February 15 at a news conference 
at the annual meeting of the American Association for the Advancement of Science. Deferring judgment to such 
autonomous, data-probing systems may lead to faulty conclusions, she warned.